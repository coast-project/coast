#! /bin/sh
set -e # abort on first error

if [ "$1" = '--help' -o "$1" = '-h' ]
then
	cat <<EOF
Synopsis: $0 [<TESTNAME> ...]

The purpose of this script is to build and run tests and measure performance.
The results are saved into CSV files to be able to compare the differences
between 32-bit and 64-bit builds.

Prerequisites:

  * virtual ENV for COAST has to be activated already
  * perf (linux-tools)
  * Valgrind

Usage:
------
This will run all tests of COAST that are known to work:

	./perf_time 

This is how you can select a set of tests:

	./perf_time CoastFoundationBaseTest CoastRegexTest

It'll measure the performance of the test suite of both the 64-bit and
the 32-bit build.

The results go into files in the perf_results/ directory.  To get a nice
comparison view of the results of one test, try something like this:

	vim -O perf/CoastFoundationPerfTest-*_optimized.csv
EOF
	exit 0
fi

# TODO ideas:
# * make archbits selectable (32/64)
# * make test methods selectable (time,valgrind,perf)

#if [ $# -ne 2 ]
#then
#	cat <<EOF >&2
#Example:
#	$0 CoastFoundationBaseTest CoastRegexTest
#
#For help, run:
#	$0 --help
#EOF
#	exit 1
#fi

which perf >/dev/null || { echo "No perf found." >&2; exit 1; }
which valgrind >/dev/null || { echo "No valgrind found." >&2; exit 1; }


NTIMES="$(readlink -f `dirname $0`/ntimes)" # absolute path to ntimes utility

PERF_DIR="$PWD/perf_results"
mkdir -p $PERF_DIR

cd `dirname $0`/.. # root directory of COAST

# GET LIST OF TESTS
ALL_TESTS=`mktemp`
#scons -u --showtargets | grep '^ - .*Test$'| cut -d' ' -f3 > $ALL_TESTS

# FIXME: hardcoded subset of tests that used to fail on 64-bit
cat <<EOF > $ALL_TESTS
CoastStorageTest
EOF
#CoastFoundationBaseTest
#CoastEBCDICTest
#CoastFoundationAnythingOptionalTest
#CoastFoundationIOTest
#CoastFoundationMiscellaneousTest
#CoastFoundationPerfTest
#CoastFoundationTest
#CoastFoundationTimeTest
#CoastMTFoundationTest
#CoastSystemFunctionsTest
#CoastRegexTest

#CoastFoundationPerfTest

echo "# Tests to be run:  ######################################" >&2
sed -e 's/^/	/' $ALL_TESTS >&2
ntests=`wc -l < $ALL_TESTS`
echo "# ($ntests tests in total)  #############################" >&2
echo "# Press return to confirm..." >&2
read confirmation
#set -x # print exact commands

START_TIME=`date`

for ARCHBITS in 64 32
do
	BUILDCFG="debug"
	SCONSFLAGS="--ignore-missing --with-src-boost=3rdparty/boost --with-src-zlib=3rdparty/zlib --with-bin-openssl=3rdparty/openssl --build-cfg=$BUILDCFG --archbits=$ARCHBITS" # --warnlevel=medium --enable-Trace" # --config=force 

	# BUILD
BUILD_LOG_DIR="$PERF_DIR/01_build"
	cat <<EOF >&2

##############################################################################
# BUILDING ...
#
# ARCHBITS=$ARCHBITS
# BUILDCFG=$BUILDCFG
# SCONSFLAGS=$SCONSFLAGS
# BUILD_LOG_DIR=$BUILD_LOG_DIR
##############################################################################
EOF
	mkdir -p $BUILD_LOG_DIR
	( set -x; scons $SCONSFLAGS `cat $ALL_TESTS`)

	# WARMUP
WARMUP_LOG_DIR="$PERF_DIR/02_warmup"
	cat <<EOF >&2

##############################################################################
# WARMUP ...
# WARMUP_LOG_DIR=$WARMUP_LOG_DIR
##############################################################################
EOF
	mkdir -p $WARMUP_LOG_DIR
cat $ALL_TESTS
	cat $ALL_TESTS | while read TESTNAME
	do
		echo "#------------------------------------------------------------------------" >&2
		echo "# (WARMUP) Running test $TESTNAME ... ###################################" >&2
		( set -x; scons $SCONSFLAGS --run-force $TESTNAME)
	done

	##
	# MEASUREMENT
	#

	# TIME-BASED
	cat <<EOF >&2

##############################################################################
# TIME-BASED MEASUREMENT ...
##############################################################################
EOF
	cat $ALL_TESTS | while read TESTNAME
	do
		echo "#------------------------------------------------------------------------" >&2
		echo "# Running test $TESTNAME ... ########################" >&2
		TIME_RESULT=$PERF_DIR/time/${TESTNAME}-${ARCHBITS}_${BUILDCFG}.csv
		mkdir -p `dirname $TIME_RESULT`

		# write CSV header if file doesn't exist yet
		if [ ! -e $TIME_RESULT ];
		then
			echo "user[s],system[s],real[s],cpu,maxres[KB],avgres[KB],avgunshared[KB],avgunsharedstack[KB],swaps" > $TIME_RESULT
		fi
		echo "# $START_TIME" >> $TIME_RESULT
		
		# run test n times and log statistics
		( set -x; scons $SCONSFLAGS --run-force --runparams="-x /usr/bin/time -x '-f' -x '%U,%S,%e,%P,%M,%t,%D,%p,%W' -x '--output=$TIME_RESULT' -x '--append' -x $NTIMES -x 5 -- -all" $TESTNAME >$PERF_DIR/time/${TESTNAME}-${ARCHBITS}_${BUILDCFG}.log 2>&1) || { echo "Test $TESTNAME with ARCHBITS=$ARCHBITS failed." >&2; exit 1; }
	done

	# VALGRIND-BASED
	cat <<EOF >&2

##############################################################################
# VALGRIND-BASED MEASUREMENT ...
##############################################################################
EOF
	cat $ALL_TESTS | while read TESTNAME
	do
		echo "#------------------------------------------------------------------------" >&2
		echo "# Running test $TESTNAME ... ########################" >&2
		VALGRIND_RESULT=$PERF_DIR/valgrind/${TESTNAME}-${ARCHBITS}_${BUILDCFG}.valgrind
		mkdir -p `dirname $VALGRIND_RESULT`
		touch $VALGRIND_RESULT # needed
		( set -x; scons $SCONSFLAGS --run-force --runparams="-x valgrind -x '--leak-check=full' -x '--log-file=$VALGRIND_RESULT' -x '--show-leak-kinds=all' -x -v -- -all" $TESTNAME >$PERF_DIR/valgrind/${TESTNAME}-${ARCHBITS}_${BUILDCFG}.log 2>&1) || { echo "Test $TESTNAME with ARCHBITS=$ARCHBITS failed." >&2; exit 1; }
	done


	# PERF-BASED
	cat <<EOF >&2

##############################################################################
# PERF-BASED MEASUREMENT ...
##############################################################################
EOF
	cat $ALL_TESTS | while read TESTNAME
	do
		echo "#------------------------------------------------------------------------" >&2
		echo "# Running test $TESTNAME ... ########################" >&2
		PERF_RESULT=$PERF_DIR/perf/${TESTNAME}-${ARCHBITS}_${BUILDCFG}.perf
		mkdir -p `dirname $PERF_RESULT`
		#touch $PERF_RESULT # needed
		( set -x; scons $SCONSFLAGS --run-force --runparams="-x perf -x record -x '-o$PERF_RESULT' -- -all" $TESTNAME >$PERF_DIR/perf/${TESTNAME}-${ARCHBITS}_${BUILDCFG}.log 2>&1) || { echo "Test $TESTNAME with ARCHBITS=$ARCHBITS failed." >&2; exit 1; }
	done
done

set +x
echo "# Performance measurement done. ################################" >&2

#! /bin/sh
. `dirname $0`/lib/measure_utils.sh
which perf >/dev/null || { echo "No perf found." >&2; exit 1; }

# DIFF COMMAND
print_diff_cmd() {
	echo "perf diff perf_results/perf/${DIFF_TEST}-32_${BUILDCFG}.perf perf_results/perf/${DIFF_TEST}-64_${BUILDCFG}.perf | c++filt | less"
}

# EXPORT
export_as_csv() (
	echo "CSV export for perf doesn't make sense. Use with_perf_stat instead." >&2
	return 1
)

# Measures performance of $ALL_TESTS using `perf`.
#
# Depends on:
#   * measure_utils.sh
#   * `perf`
#   * $TEST_NAMES
#   * $PERF_DIR
#   * $BUILDCFG
#   * $ARCHBITS
measure_performance() {
	SCONSFLAGS="--ignore-missing --with-src-boost=3rdparty/boost --with-src-zlib=3rdparty/zlib --with-bin-openssl=3rdparty/openssl --build-cfg=$BUILDCFG --archbits=$ARCHBITS" # --warnlevel=medium --enable-Trace" # --config=force 
	build `cat $TEST_NAMES`

	##
	# MEASUREMENT
	#
	progress "PERF-BASED MEASUREMENT ..."
	for TESTNAME in `cat $TEST_NAMES`
	do
		start $TESTNAME
		RESULT=$PERF_DIR/perf/${TESTNAME}-${ARCHBITS}_${BUILDCFG}.perf
		mkdir -p `dirname $RESULT`
		log="$PERF_DIR/perf/${TESTNAME}-${ARCHBITS}_${BUILDCFG}.log"
		if log_cmd scons $SCONSFLAGS --run-force --runparams="-x perf -x record -x -F99 -x -g -x '-o$RESULT' -- -all" $TESTNAME > $log >&2
		then
			measurement_successful $TESTNAME
		else
			measurement_failed $TESTNAME $log
		fi

	done
}

##
# MAIN
#

BUILDCFG="optimized"
[ -n "$DIFF_TEST" ] && { print_diff_cmd; exit; }
$EXPORT && { export_as_csv; exit $?; }

measure_performance_for_selected_archbits
